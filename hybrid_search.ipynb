{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef115872-a75b-4023-b07c-b144340b24e5",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0ea83ee7-ae54-481c-90fc-5d5d05c71a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Stream the dataset to avoid loading everything in memory\n",
    "ds = load_dataset(\"eloukas/edgar-corpus\", \"full\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425969ef-3131-4c44-ba49-b0be0e27d01b",
   "metadata": {},
   "source": [
    "### 1.1 Filter the dataset for AIG and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd15a3c7-9209-4e54-a30c-dfe68b411840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 22 AIG rows to aig_edgar.jsonl.gz\n"
     ]
    }
   ],
   "source": [
    "# it never holds the whole dataset in memory, and the gzip keeps the file small.\n",
    "import json, gzip, os\n",
    "\n",
    "AIG_CIK = \"0000005272\"   # AIG\n",
    "OUT_PATH = \"aig_edgar.jsonl.gz\"  # compact on-disk buffer for Spark\n",
    "\n",
    "# Write only matching rows to newline-delimited JSON (gzipped)\n",
    "count = 0\n",
    "with gzip.open(OUT_PATH, \"wt\", encoding=\"utf-8\") as f:\n",
    "    for row in ds:\n",
    "        # rows have keys like: filename, cik, year, section_1, section_1A, ...\n",
    "        if str(row.get(\"cik\", \"\")).zfill(10) == AIG_CIK:\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "            count += 1\n",
    "\n",
    "print(f\"Wrote {count} AIG rows to {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3f39a-25f3-4ad2-9f84-f1e6c5f4c180",
   "metadata": {},
   "source": [
    "### 1.2 Using Spark to create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf01030-3a65-42d0-9d21-2621719f4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/10 01:07:57 WARN Utils: Your hostname, Anants-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.163 instead (on interface en0)\n",
      "25/09/10 01:07:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/10 01:08:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----+\n",
      "|filename     |cik       |year|\n",
      "+-------------+----------+----+\n",
      "|5272_1994.txt|0000005272|1994|\n",
      "|5272_1995.txt|0000005272|1995|\n",
      "|5272_1998.txt|0000005272|1998|\n",
      "|5272_1999.txt|0000005272|1999|\n",
      "|5272_2000.txt|0000005272|2000|\n",
      "|5272_2001.txt|0000005272|2001|\n",
      "|5272_2003.htm|0000005272|2003|\n",
      "|5272_2004.htm|0000005272|2004|\n",
      "|5272_2005.htm|0000005272|2005|\n",
      "|5272_2006.htm|0000005272|2006|\n",
      "+-------------+----------+----+\n",
      "only showing top 10 rows\n",
      "Saved AIG subset to parquet_aig_edgar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "OUT_PATH = \"aig_edgar.jsonl.gz\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"AIG-EDGAR\")\n",
    "    # tweak as you like; driver mem helps if you inspect a lot at once\n",
    "    .config(\"spark.driver.memory\", \"6g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Read the gzipped JSONL directly\n",
    "aig_df = spark.read.json(OUT_PATH)\n",
    "\n",
    "# (Optional) normalize CIK to 10-digit string for consistency\n",
    "from pyspark.sql.functions import lpad, col\n",
    "aig_df = aig_df.withColumn(\"cik\", lpad(col(\"cik\").cast(\"string\"), 10, \"0\"))\n",
    "\n",
    "# Inspect a few rows\n",
    "aig_df.select(\"filename\", \"cik\", \"year\").show(10, truncate=False)\n",
    "\n",
    "# Persist to Parquet (columnar, splittable, great for Spark)\n",
    "PARQUET_DIR = \"parquet_aig_edgar\"\n",
    "aig_df.write.mode(\"overwrite\").parquet(PARQUET_DIR)\n",
    "\n",
    "print(f\"Saved AIG subset to {PARQUET_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d8bbbae-1596-4792-bac3-e8ec901f6eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>filename</th>\n",
       "      <th>section_1</th>\n",
       "      <th>section_10</th>\n",
       "      <th>section_11</th>\n",
       "      <th>section_12</th>\n",
       "      <th>section_13</th>\n",
       "      <th>section_14</th>\n",
       "      <th>section_15</th>\n",
       "      <th>section_1A</th>\n",
       "      <th>...</th>\n",
       "      <th>section_4</th>\n",
       "      <th>section_5</th>\n",
       "      <th>section_6</th>\n",
       "      <th>section_7</th>\n",
       "      <th>section_7A</th>\n",
       "      <th>section_8</th>\n",
       "      <th>section_9</th>\n",
       "      <th>section_9A</th>\n",
       "      <th>section_9B</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000005272</td>\n",
       "      <td>5272_1994.txt</td>\n",
       "      <td>ITEM 1. BUSINESS\\nAmerican International Group...</td>\n",
       "      <td>ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...</td>\n",
       "      <td>ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...</td>\n",
       "      <td>ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...</td>\n",
       "      <td>ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...</td>\n",
       "      <td>ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...</td>\n",
       "      <td>ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...</td>\n",
       "      <td>ITEM 6. SELECTED FINANCIAL DATA\\nAMERICAN INTE...</td>\n",
       "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
       "      <td></td>\n",
       "      <td>ITEM 8. FINANCIAL STATEMENTS AND SUPPLEMENTARY...</td>\n",
       "      <td>ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000005272</td>\n",
       "      <td>5272_1995.txt</td>\n",
       "      <td>ITEM 1. BUSINESS\\nAmerican International Group...</td>\n",
       "      <td>ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...</td>\n",
       "      <td>ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...</td>\n",
       "      <td>ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...</td>\n",
       "      <td>ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...</td>\n",
       "      <td>ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...</td>\n",
       "      <td>ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...</td>\n",
       "      <td>ITEM 6. SELECTED FINANCIAL DATA AMERICAN INTER...</td>\n",
       "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
       "      <td></td>\n",
       "      <td>ITEM 8. Financial Statements and Supplementary...</td>\n",
       "      <td>ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cik       filename  \\\n",
       "0  0000005272  5272_1994.txt   \n",
       "1  0000005272  5272_1995.txt   \n",
       "\n",
       "                                           section_1  \\\n",
       "0  ITEM 1. BUSINESS\\nAmerican International Group...   \n",
       "1  ITEM 1. BUSINESS\\nAmerican International Group...   \n",
       "\n",
       "                                          section_10  \\\n",
       "0  ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...   \n",
       "1  ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...   \n",
       "\n",
       "                                          section_11  \\\n",
       "0  ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...   \n",
       "1  ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...   \n",
       "\n",
       "                                          section_12  \\\n",
       "0  ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...   \n",
       "1  ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...   \n",
       "\n",
       "                                          section_13  \\\n",
       "0  ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...   \n",
       "1  ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...   \n",
       "\n",
       "                                          section_14 section_15 section_1A  \\\n",
       "0  ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...                         \n",
       "1  ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...                         \n",
       "\n",
       "   ...                                          section_4  \\\n",
       "0  ...  ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...   \n",
       "1  ...  ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...   \n",
       "\n",
       "                                           section_5  \\\n",
       "0  ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...   \n",
       "1  ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...   \n",
       "\n",
       "                                           section_6  \\\n",
       "0  ITEM 6. SELECTED FINANCIAL DATA\\nAMERICAN INTE...   \n",
       "1  ITEM 6. SELECTED FINANCIAL DATA AMERICAN INTER...   \n",
       "\n",
       "                                           section_7 section_7A  \\\n",
       "0  ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...              \n",
       "1  ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...              \n",
       "\n",
       "                                           section_8  \\\n",
       "0  ITEM 8. FINANCIAL STATEMENTS AND SUPPLEMENTARY...   \n",
       "1  ITEM 8. Financial Statements and Supplementary...   \n",
       "\n",
       "                                           section_9 section_9A section_9B  \\\n",
       "0  ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...                         \n",
       "1  ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...                         \n",
       "\n",
       "   year  \n",
       "0  1994  \n",
       "1  1995  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aig_df.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f9276-880d-4b5a-aa80-6f9b85aa760c",
   "metadata": {},
   "source": [
    "## Solution 1: \n",
    "    - Using the Hybrid vector search/store based approach \n",
    "    - Passing Question to Hybrid retreiver to get relevant document \n",
    "    - Passing the fetched Document into LLM to extract the detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac2efd-caaf-4670-9f59-3d0aa69f98c8",
   "metadata": {},
   "source": [
    "### 1.1. Loading Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d279a2-3927-44b4-9df3-29c2b1bfd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import google.generativeai as genai\n",
    "# api_key = \"AIzaSyDz3kL0XL7QogHsDPh_g596Raj2CbpyMmQ\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = api_key # or set in your shell\n",
    "# genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41d2eb5b-306d-4410-b249-4aa075f625bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# dim = len(embeddings.embed_query(\"dimension probe\"))\n",
    "# print(\"Embedding dimension:\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7646f6f0-6ddb-4a92-9361-97e0f99c6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/kfpdlprs34v26w9mq48wpb200000gn/T/ipykernel_69273/3952074370.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/Users/anant/anaconda3/envs/spark/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "dim = len(embeddings.embed_query(\"dimension probe\"))\n",
    "print(\"Embedding dimension:\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0fa7ce89-1e49-41a8-bb08-463ffa4e613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aig_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "48361e25-c8a0-43dc-9d4a-814af01b289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.year.isin(['2004', '2008', '2012', '2016', '2020'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "055313a5-6d21-4ac9-87b1-d78c6e2afa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from typing import List, Iterable\n",
    "from uuid import uuid4\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "try:\n",
    "    from langchain_experimental.text_splitter import SemanticChunker\n",
    "    _HAS_SEM = True\n",
    "except Exception:\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    _HAS_SEM = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d0a6a-1694-45b2-90c1-12af5b067c2a",
   "metadata": {},
   "source": [
    "### 1.2 Preparing Document for Injestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7b0d505-7721-431a-8a73-3b2ff19cbbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_splitter(emb):\n",
    "    \"\"\"\n",
    "    Semantic splitter that finds natural breakpoints; falls back to\n",
    "    a high-quality character-based splitter.\n",
    "    \"\"\"\n",
    "    if _HAS_SEM:\n",
    "        # Breakpoints chosen via embedding similarity changes.\n",
    "        # 95th percentile is a good default for long 10-K sections.\n",
    "        return SemanticChunker(\n",
    "            emb,\n",
    "            breakpoint_threshold_type=\"percentile\",\n",
    "            breakpoint_threshold_amount=95,\n",
    "        )\n",
    "    else:\n",
    "        # Safe default if semantic chunker isn't available.\n",
    "        return RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1200,\n",
    "            chunk_overlap=150,\n",
    "            add_start_index=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def _is_nonempty_text(x) -> bool:\n",
    "    if x is None:\n",
    "        return False\n",
    "    if isinstance(x, float) and math.isnan(x):\n",
    "        return False\n",
    "    return bool(str(x).strip())\n",
    "\n",
    "\n",
    "def _iter_section_chunks(\n",
    "    df: pd.DataFrame,\n",
    "    splitter,\n",
    "):\n",
    "    \"\"\"Yield chunked Documents with rich metadata from a wide SEC sections DF.\"\"\"\n",
    "    # discover section columns dynamically\n",
    "    section_cols: List[str] = [c for c in df.columns if c.startswith(\"section_\")]\n",
    "\n",
    "    for row in df.itertuples(index=False):\n",
    "        filename = str(getattr(row, \"filename\"))\n",
    "        cik = str(getattr(row, \"cik\"))\n",
    "        year = int(getattr(row, \"year\"))\n",
    "\n",
    "        for sec in section_cols:\n",
    "            raw_text = getattr(row, sec)\n",
    "            if not _is_nonempty_text(raw_text):\n",
    "                continue\n",
    "\n",
    "            text = str(raw_text).strip()\n",
    "            # parent (section) identity\n",
    "            section_id = f\"{filename}#{sec}\"\n",
    "            section_title = text.splitlines()[0][:160] if text else \"\"\n",
    "\n",
    "            # split into semantic chunks\n",
    "            chunks: List[str] = splitter.split_text(text)\n",
    "\n",
    "            for idx, chunk in enumerate(chunks):\n",
    "                # stable per-chunk id (handy if you later want parent-child mapping)\n",
    "                doc_id = f\"{section_id}::chunk{idx}\"\n",
    "                meta = {\n",
    "                    \"doc_id\": doc_id,            # unique id for this chunk\n",
    "                    \"section_id\": section_id,    # parent section id\n",
    "                    \"section\": sec,              # e.g., \"section_10\"\n",
    "                    \"section_title\": section_title,\n",
    "                    \"filename\": filename,\n",
    "                    \"cik\": cik,\n",
    "                    \"year\": year,\n",
    "                    \"chunk_index\": idx,\n",
    "                }\n",
    "                yield Document(page_content=chunk, metadata=meta)\n",
    "                \n",
    "splitter = _make_splitter(embeddings)\n",
    "docs = list(_iter_section_chunks(df, splitter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d21f3-f1ad-44ee-8d55-574229e0544c",
   "metadata": {},
   "source": [
    "### 1.3 Creating Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a27f575-6036-4eb0-b512-9b390236ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "if not docs:\n",
    "    raise ValueError(\"No non-empty section text found to index.\")\n",
    "\n",
    "vstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Optional: persist to disk\n",
    "vstore.save_local(\"faiss_edgar_sections_v2\")\n",
    "\n",
    "vector_retriever = vstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "\n",
    "# Create a BM25Retriever for keyword search\n",
    "bm25_retriever = BM25Retriever.from_documents(docs, k=6)\n",
    "\n",
    "# --- combine them ---\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.5, 0.5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28e27088-6d19-4783-86a7-f86b99da70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction_prompt = \"\"\"\n",
    "# ## Persona\n",
    "# - Extract the exact data and present to the user\n",
    "\n",
    "# ## Given context:\n",
    "# {context}\n",
    "\n",
    "# ## Question: \n",
    "# {question} \n",
    "# \"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d116a33-d0ca-4ce7-9b9a-c05b9e5d2c35",
   "metadata": {},
   "source": [
    "### 1.4 Prompt to extract details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b7982c4c-a77b-4e3f-8694-9d6edd49d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_detail_v3 = \"\"\"\n",
    "## Role\n",
    "You are an extraction analyst. Read the provided document content and metadata to extract AIG facts.\n",
    "\n",
    "## Targets (extract EXACT text as written in the document body)\n",
    "- Total Revenue\n",
    "- Net income (loss) attributable to AIG\n",
    "- Auditor firm (e.g., “PricewaterhouseCoopers LLP”, “KPMG LLP”, “Deloitte & Touche LLP”)\n",
    "\n",
    "## Metadata Rules (authoritative)\n",
    "- year: use year if provided in metadata; do not infer from text if metadata exists.\n",
    "- section/source:\n",
    "  - Prefer parent_id (e.g., \"5272_2020.htm#section_9B\") if present.\n",
    "  - Else use section (e.g., \"section_9B\").\n",
    "  - If neither present, use the clearest section header found in the text (e.g., \"Item 7\", \"Item 8\").\n",
    "\n",
    "## Hints (don’t guess)\n",
    "- “Total Revenue” may appear as “Total revenues”, “Consolidated total revenues”.\n",
    "- “Net income (loss) attributable to AIG” might appear as “Net income attributable to AIG/common shareholders”.\n",
    "- For the auditor, return the firm NAME only (not the report title).\n",
    "- If any one of the three target fields (Total Revenue, Net income..., Auditor) is missing, return exactly: None\n",
    "\n",
    "## Output (STRICT)\n",
    "- Return EXACTLY one line with 5 fields separated by \" || \"\n",
    "  1) Total Revenue\n",
    "  2) Net income (loss) attributable to AIG\n",
    "  3) Auditor firm\n",
    "  4) year\n",
    "  5) section/source (prefer parent_id; else section; else header text)\n",
    "- No extra text, labels, or quotes.\n",
    "- Preserve numbers/formatting as written (keep $, commas, parentheses, “million/billion”).\n",
    "\n",
    "## Edge Rules\n",
    "- If both “Net income” and “Net loss” variants appear, choose the one explicitly “attributable to AIG”.\n",
    "- Prefer first unambiguous occurrence in MD&A/Financial Statements (Items 7/8) when multiple appear.\n",
    "- Never infer the auditor from signatures without the firm’s name.\n",
    "\n",
    "## Tiny Examples\n",
    "\n",
    "[Example A — all present]\n",
    "Meta: year=2019, section=section_7, parent_id=5272_2019.htm#section_7\n",
    "Text: “Total revenues were $52.1 billion… Net income (loss) attributable to AIG was $(6.7) billion… audited by PricewaterhouseCoopers LLP…”\n",
    "Output:\n",
    "$52.1 billion || $(6.7) billion || PricewaterhouseCoopers LLP || 2019 || 5272_2019.htm#section_7\n",
    "\n",
    "[Example B — missing a target → None]\n",
    "Meta: year=2016, section=section_7A, parent_id=5272_2016.htm#section_7A\n",
    "Text: “Total revenues were $39.8 billion… [no ‘net income attributable to AIG’]…”\n",
    "Output:\n",
    "None\n",
    "\n",
    "## Document (body text):\n",
    "{context}\n",
    "\n",
    "## Question:\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9de35f80-4efd-405f-ba54-95c4afd998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI # Import the Google Generative AI class\n",
    "import os\n",
    "\n",
    "# Optional: Set your API key if it's not already in your environment variables\n",
    "# from google.colab import userdata # Use this if you are in a Colab notebook\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "prompt_template_v1 = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", extract_detail_v3)\n",
    "])\n",
    "\n",
    "# Choose model: \"gemini-1.5-flash\" (fast/cheap) or \"gemini-1.5-pro\" (higher quality)\n",
    "llm_1 = ChatVertexAI(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=1024,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    api_transport=\"grpc\",   # good perf\n",
    ")\n",
    "\n",
    "# # Create the RAG chain\n",
    "rag_chain_v1 = (\n",
    "    {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template_v1\n",
    "    | llm_1\n",
    ")\n",
    "\n",
    "# Invoke the chain with a query\n",
    "response = rag_chain_v1.invoke(\"Total revenue of aig in 2016\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5652bcf7-c9c8-40cf-b509-715fa94b1be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "34bdf80d-5320-456e-ac54-ab27e9e55612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the chain with a query\n",
    "response = rag_chain_v1.invoke(\"who is the auditor since 2003 to 2015.\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b6b59-c69c-443a-9634-350e2e4396d2",
   "metadata": {},
   "source": [
    "## Solution 2: \n",
    " - Passing the document directly to LLM and extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84936c7-b91e-4b9b-aa6c-3441c0017924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = df[df.year.isin(['2016', '2017', '2018', '2019', '2020'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c483cfa-9399-4b5b-af2f-928b76c42b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "dim = len(embeddings.embed_query(\"dimension probe\"))\n",
    "print(\"Embedding dimension:\", dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ab991-f3b1-4767-873e-fbb40fdf12b6",
   "metadata": {},
   "source": [
    "### 2.1 Preparing Parent Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8b6f8d20-907c-48f4-a767-1d92441c2948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 76 parent docs across 20 sections.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "# Identify section columns dynamically\n",
    "section_cols: List[str] = [c for c in df.columns if c.startswith(\"section_\")]\n",
    "\n",
    "# Build parent docs (one per non-empty section cell)\n",
    "parents: List[Document] = []\n",
    "parent_ids: List[str] = []\n",
    "\n",
    "for row in df.itertuples(index=False):\n",
    "    base_meta = {\n",
    "        \"filename\": getattr(row, \"filename\"),\n",
    "        \"cik\": getattr(row, \"cik\"),\n",
    "        \"year\": getattr(row, \"year\"),\n",
    "    }\n",
    "    for sec in section_cols:\n",
    "        content = getattr(row, sec)\n",
    "        if not content or not str(content).strip():\n",
    "            continue\n",
    "\n",
    "        parent_id = f\"{base_meta['filename']}#{sec}\"   # stable per (file, section)\n",
    "        doc = Document(\n",
    "            page_content=str(content),\n",
    "            metadata={\n",
    "                **base_meta,\n",
    "                \"section\": sec,\n",
    "                \"parent_id\": parent_id,\n",
    "            },\n",
    "        )\n",
    "        parents.append(doc)\n",
    "        parent_ids.append(parent_id)\n",
    "\n",
    "print(f\"Prepared {len(parents)} parent docs across {len(section_cols)} sections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ccae91-0f80-4faa-9840-382c94eca79b",
   "metadata": {},
   "source": [
    "### 2.2 (optional) chunking the parent document semantically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f68b99f2-2681-4821-b45f-8af014b99e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 703 child chunks from 96 parents (avg 7.32 chunks/parent). Mode: fallback (recursive).\n",
      "5272_2016.htm#section_1::chunk-0000 section_1 7994\n",
      "5272_2016.htm#section_1::chunk-0001 section_1 8157\n",
      "5272_2016.htm#section_1::chunk-0002 section_1 7895\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# If you use OpenAI:\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# If you use Google Gemini:\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
    "\n",
    "def chunk_parents_semantic(\n",
    "    parents: List[Document],\n",
    "    embeddings,  # any LangChain Embeddings implementation\n",
    "    breakpoint_threshold_type: str = \"percentile\",   # \"percentile\" | \"standard_deviation\" | \"interquartile\"\n",
    "    breakpoint_threshold_amount: float = 95,         # used when type=\"percentile\"\n",
    "    overlap_chars: int = 200,                         # optional context overlap between adjacent chunks\n",
    ") -> Tuple[List[Document], List[str], Dict[str, List[str]]]:\n",
    "    \"\"\"\n",
    "    Split each parent Document into semantically coherent child Documents.\n",
    "    Returns:\n",
    "      - children: list of child chunk Documents\n",
    "      - children_ids: list of chunk_ids\n",
    "      - children_by_parent: mapping from parent_id to list of chunk_ids\n",
    "    \"\"\"\n",
    "    # Try to import SemanticChunker; if not available, fall back to RecursiveCharacterTextSplitter\n",
    "    try:\n",
    "        from langchain_text_splitters import SemanticChunker\n",
    "        semantic_splitter = SemanticChunker(\n",
    "            embeddings=embeddings,\n",
    "            breakpoint_threshold_type=breakpoint_threshold_type,\n",
    "            breakpoint_threshold_amount=breakpoint_threshold_amount,\n",
    "        )\n",
    "        use_semantic = True\n",
    "    except Exception:\n",
    "        # Fallback: character-based splitter\n",
    "        from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "        semantic_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=8000,\n",
    "            chunk_overlap=overlap_chars,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        )\n",
    "        use_semantic = False\n",
    "\n",
    "    children: List[Document] = []\n",
    "    children_ids: List[str] = []\n",
    "    children_by_parent: Dict[str, List[str]] = {}\n",
    "\n",
    "    for pdoc in parents:\n",
    "        parent_id = pdoc.metadata[\"parent_id\"]\n",
    "\n",
    "        # Create chunk docs; prefer create_documents if supported\n",
    "        try:\n",
    "            chunks: List[Document] = semantic_splitter.create_documents(\n",
    "                texts=[pdoc.page_content],\n",
    "                metadatas=[pdoc.metadata],\n",
    "            )\n",
    "        except Exception:\n",
    "            # Some splitters only expose split_text\n",
    "            texts = semantic_splitter.split_text(pdoc.page_content)\n",
    "            chunks = [Document(page_content=t, metadata=dict(pdoc.metadata)) for t in texts]\n",
    "\n",
    "        # Optional character overlap (prefix the current chunk with the tail of the previous one)\n",
    "        if overlap_chars and len(chunks) > 1:\n",
    "            prev_text = \"\"\n",
    "            for i, ch in enumerate(chunks):\n",
    "                if i > 0 and prev_text:\n",
    "                    prefix = prev_text[-overlap_chars:]\n",
    "                    ch.page_content = prefix + ch.page_content\n",
    "                prev_text = ch.page_content\n",
    "\n",
    "        # Add stable IDs + extra metadata\n",
    "        for i, ch in enumerate(chunks):\n",
    "            chunk_id = f\"{parent_id}::chunk-{i:04d}\"\n",
    "            ch.metadata.update({\n",
    "                \"parent_id\": parent_id,\n",
    "                \"chunk_index\": i,\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"chunk_size\": len(ch.page_content),\n",
    "                \"chunking\": \"semantic\" if use_semantic else \"recursive_fallback\",\n",
    "                \"breakpoint_threshold_type\": breakpoint_threshold_type if use_semantic else None,\n",
    "                \"breakpoint_threshold_amount\": breakpoint_threshold_amount if use_semantic else None,\n",
    "            })\n",
    "\n",
    "            children.append(ch)\n",
    "            children_ids.append(chunk_id)\n",
    "            children_by_parent.setdefault(parent_id, []).append(chunk_id)\n",
    "\n",
    "    print(\n",
    "        f\"Built {len(children)} child chunks from {len(parents)} parents \"\n",
    "        f\"(avg {len(children)/max(1,len(parents)):.2f} chunks/parent). \"\n",
    "        f\"Mode: {'semantic' if use_semantic else 'fallback (recursive)'}.\"\n",
    "    )\n",
    "    return children, children_ids, children_by_parent\n",
    "\n",
    "children, children_ids, children_by_parent = chunk_parents_semantic(\n",
    "    parents,\n",
    "    embeddings=embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=95,   # higher => fewer, larger chunks\n",
    "    overlap_chars=200,\n",
    ")\n",
    "\n",
    "# Peek at a couple of chunks\n",
    "for d in children[:3]:\n",
    "    print(d.metadata[\"chunk_id\"], d.metadata.get(\"section\"), len(d.page_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ddb75-362d-4d59-96fb-00ee26eb0e63",
   "metadata": {},
   "source": [
    "### 2.3 Prompt to extract details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2745fc3e-3a41-4859-8bcc-b1ac934c76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract_Details = \"\"\"\n",
    "## Role\n",
    "You are an extraction analyst. Read the provided document content and metadata to extract AIG facts.\n",
    "\n",
    "## Targets (extract EXACT text as written in the document body)\n",
    "- Total Revenue\n",
    "- Net income (loss) attributable to AIG\n",
    "- Auditor firm (e.g., “PricewaterhouseCoopers LLP”, “KPMG LLP”, “Deloitte & Touche LLP”)\n",
    "\n",
    "## Metadata Rules (authoritative)\n",
    "- year: use {year} if provided in metadata; do not infer from text if metadata exists.\n",
    "- section/source:\n",
    "  - Prefer {parent_id} (e.g., \"5272_2020.htm#section_9B\") if present.\n",
    "  - Else use {section} (e.g., \"section_9B\").\n",
    "  - If neither present, use the clearest section header found in the text (e.g., \"Item 7\", \"Item 8\").\n",
    "\n",
    "## Hints (don’t guess)\n",
    "- “Total Revenue” may appear as “Total revenues”, “Consolidated total revenues”.\n",
    "- “Net income (loss) attributable to AIG” might appear as “Net income attributable to AIG/common shareholders”.\n",
    "- For the auditor, return the firm NAME only (not the report title).\n",
    "- If any one of the three target fields (Total Revenue, Net income..., Auditor) is missing, return exactly: None\n",
    "\n",
    "## Output (STRICT)\n",
    "- Return EXACTLY one line with 5 fields separated by \" || \"\n",
    "  1) Total Revenue\n",
    "  2) Net income (loss) attributable to AIG\n",
    "  3) Auditor firm\n",
    "  4) year\n",
    "  5) section/source (prefer parent_id; else section; else header text)\n",
    "- No extra text, labels, or quotes.\n",
    "- Preserve numbers/formatting as written (keep $, commas, parentheses, “million/billion”).\n",
    "\n",
    "## Edge Rules\n",
    "- If both “Net income” and “Net loss” variants appear, choose the one explicitly “attributable to AIG”.\n",
    "- Prefer first unambiguous occurrence in MD&A/Financial Statements (Items 7/8) when multiple appear.\n",
    "- Never infer the auditor from signatures without the firm’s name.\n",
    "\n",
    "## Tiny Examples\n",
    "\n",
    "[Example A — all present]\n",
    "Meta: year=2019, section=section_7, parent_id=5272_2019.htm#section_7\n",
    "Text: “Total revenues were $52.1 billion… Net income (loss) attributable to AIG was $(6.7) billion… audited by PricewaterhouseCoopers LLP…”\n",
    "Output:\n",
    "$52.1 billion || $(6.7) billion || PricewaterhouseCoopers LLP || 2019 || 5272_2019.htm#section_7\n",
    "\n",
    "[Example B — missing a target → None]\n",
    "Meta: year=2016, section=section_7A, parent_id=5272_2016.htm#section_7A\n",
    "Text: “Total revenues were $39.8 billion… [no ‘net income attributable to AIG’]…”\n",
    "Output:\n",
    "None\n",
    "\n",
    "## Document (body text):\n",
    "{document}\n",
    "\n",
    "## Metadata:\n",
    "filename={filename}\n",
    "year={year}\n",
    "section={section}\n",
    "parent_id={parent_id}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47f37d-8b64-4017-b459-2394be0134c5",
   "metadata": {},
   "source": [
    "### 2.4 Setting up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2880d468-c2ce-4e36-bc73-85f6984f9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"drift-sense\")\n",
    "LOCATION  = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fe72881a-2088-4c2f-bdc0-0f21928a114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", Extract_Details)\n",
    "])\n",
    "\n",
    "# Choose model: \"gemini-1.5-flash\" (fast/cheap) or \"gemini-1.5-pro\" (higher quality)\n",
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=1024,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    api_transport=\"grpc\",   # good perf\n",
    ")\n",
    "\n",
    "rag_chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f91baa-e5c2-4def-a06e-453850683c47",
   "metadata": {},
   "source": [
    "### 2.5 Running the rag model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3c943869-ca22-4a57-a7bd-35b1d2d76816",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_details = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a7e7fe1a-fe21-42c8-9044-d6482624cf6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [03:40<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for doc in tqdm(parents):\n",
    "    # Run the chain\n",
    "    out = rag_chain.invoke({\n",
    "        \"document\": doc.page_content,\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "    })\n",
    "\n",
    "    # LangChain chat models usually return an AIMessage; fall back to str if needed\n",
    "    content = getattr(out, \"content\", out)\n",
    "    if content is None:\n",
    "        continue\n",
    "\n",
    "    text = str(content).strip()\n",
    "    \n",
    "    # Skip empty/placeholder outputs\n",
    "    if not text or text.lower() in {\"none\", \"null\", \"{}\", \"[]\"}:\n",
    "        continue\n",
    "\n",
    "    # Save either the raw text or a richer record\n",
    "    extracted_details.append({\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        # \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "        \"extracted\": text,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c554102a-b039-47ae-99ec-498198ad4819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4 items\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saved {len(extracted_details)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2646a605-2e87-415e-b24c-c8756080eddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': '5272_2004.htm',\n",
       "  'year': '2004',\n",
       "  'section': 'section_7',\n",
       "  'parent_id': '5272_2004.htm#section_7',\n",
       "  'extracted': '$98.69 billion || $9.77 billion || PricewaterhouseCoopers LLP || 2004 || 5272_2004.htm#section_7'},\n",
       " {'filename': '5272_2012.htm',\n",
       "  'year': '2012',\n",
       "  'section': 'section_8',\n",
       "  'parent_id': '5272_2012.htm#section_8',\n",
       "  'extracted': '$68,790 million || $'},\n",
       " {'filename': '5272_2016.htm',\n",
       "  'year': '2016',\n",
       "  'section': 'section_8',\n",
       "  'parent_id': '5272_2016.htm#section_8',\n",
       "  'extracted': '$52,330 million || $(849) million || PricewaterhouseCoopers LLP || 2016 || 5272_2016.htm#section_8'},\n",
       " {'filename': '5272_2020.htm',\n",
       "  'year': '2020',\n",
       "  'section': 'section_8',\n",
       "  'parent_id': '5272_2020.htm#section_8',\n",
       "  'extracted': '$47,997 million || $(5,973) million || PricewaterhouseCoopers LLP || 2020 || 5272_2020.htm#section_8'}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6b4b3-5bc0-44a7-a4c4-a7eaab715e47",
   "metadata": {},
   "source": [
    "### 2.6 Extracting the details and Saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5b824bf0-4ed3-4a23-b5a9-396a4dfa8009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '5272_2004.htm', 'year': '2004', 'section': 'section_7', 'parent_id': '5272_2004.htm#section_7', 'extracted': '$98.69 billion || $9.77 billion || PricewaterhouseCoopers LLP || 2004 || 5272_2004.htm#section_7'}\n",
      "{'filename': '5272_2012.htm', 'year': '2012', 'section': 'section_8', 'parent_id': '5272_2012.htm#section_8', 'extracted': '$68,790 million || $'}\n",
      "{'filename': '5272_2016.htm', 'year': '2016', 'section': 'section_8', 'parent_id': '5272_2016.htm#section_8', 'extracted': '$52,330 million || $(849) million || PricewaterhouseCoopers LLP || 2016 || 5272_2016.htm#section_8'}\n",
      "{'filename': '5272_2020.htm', 'year': '2020', 'section': 'section_8', 'parent_id': '5272_2020.htm#section_8', 'extracted': '$47,997 million || $(5,973) million || PricewaterhouseCoopers LLP || 2020 || 5272_2020.htm#section_8'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_df_from_extracted(recs):\n",
    "    rows = []\n",
    "    for r in recs:\n",
    "        print(r)\n",
    "        parent_id = r.get(\"parent_id\")\n",
    "        extract_details = r.get(\"extracted\").split(\"||\")\n",
    "        if len(extract_details) == 5:\n",
    "            rev_raw, net_raw, _auditor, year_str, parent = extract_details\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # derive section from the tail of parent (e.g., \"...#section_8\")\n",
    "        section = None\n",
    "        if parent and \"#\" in parent:\n",
    "            section = parent.split(\"#\", 1)[1]\n",
    "\n",
    "        rows.append({\n",
    "            \"Total revenues\": rev_raw,  # in millions\n",
    "            \"Net income (loss) attributable to AIG\": net_raw,      # in millions\n",
    "            \"year\": year_str,\n",
    "            \"auditor\": _auditor,\n",
    "            \"filename#section\": parent_id\n",
    "        })\n",
    "    return pd.DataFrame(rows, columns=[\"Total revenues\", \"Net income (loss) attributable to AIG\", \"auditor\", \"year\", \"filename#section\"])\n",
    "\n",
    "df_final = build_df_from_extracted(extracted_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6a846976-d4a6-464c-b482-ca36b28e5728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total revenues</th>\n",
       "      <th>Net income (loss) attributable to AIG</th>\n",
       "      <th>auditor</th>\n",
       "      <th>year</th>\n",
       "      <th>filename#section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$98.69 billion</td>\n",
       "      <td>$9.77 billion</td>\n",
       "      <td>PricewaterhouseCoopers LLP</td>\n",
       "      <td>2004</td>\n",
       "      <td>5272_2004.htm#section_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$52,330 million</td>\n",
       "      <td>$(849) million</td>\n",
       "      <td>PricewaterhouseCoopers LLP</td>\n",
       "      <td>2016</td>\n",
       "      <td>5272_2016.htm#section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$47,997 million</td>\n",
       "      <td>$(5,973) million</td>\n",
       "      <td>PricewaterhouseCoopers LLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>5272_2020.htm#section_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total revenues Net income (loss) attributable to AIG  \\\n",
       "0   $98.69 billion                         $9.77 billion    \n",
       "1  $52,330 million                        $(849) million    \n",
       "2  $47,997 million                      $(5,973) million    \n",
       "\n",
       "                        auditor    year         filename#section  \n",
       "0   PricewaterhouseCoopers LLP    2004   5272_2004.htm#section_7  \n",
       "1   PricewaterhouseCoopers LLP    2016   5272_2016.htm#section_8  \n",
       "2   PricewaterhouseCoopers LLP    2020   5272_2020.htm#section_8  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71e8476f-d6a0-42da-aa80-1dd48cde1a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>cik</th>\n",
       "      <th>year</th>\n",
       "      <th>variable</th>\n",
       "      <th>value_usd</th>\n",
       "      <th>unit</th>\n",
       "      <th>category_value</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2020</td>\n",
       "      <td>Total revenues</td>\n",
       "      <td>43,736</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2016</td>\n",
       "      <td>Total revenues</td>\n",
       "      <td>52,367</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2012</td>\n",
       "      <td>Total revenues</td>\n",
       "      <td>65,656</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2008</td>\n",
       "      <td>Total revenues</td>\n",
       "      <td>11,777</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2004</td>\n",
       "      <td>Total revenues</td>\n",
       "      <td>98,615</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2020</td>\n",
       "      <td>Net income (loss) attributable to AIG</td>\n",
       "      <td>-5,944</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2016</td>\n",
       "      <td>Net income (loss) attributable to AIG</td>\n",
       "      <td>3,348</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2012</td>\n",
       "      <td>Net income (loss) attributable to AIG</td>\n",
       "      <td>3,438</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2008</td>\n",
       "      <td>Net income (loss) attributable to AIG</td>\n",
       "      <td>-101,784</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2004</td>\n",
       "      <td>Net income (loss) attributable to AIG</td>\n",
       "      <td>9,731</td>\n",
       "      <td>USD millions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2020</td>\n",
       "      <td>Auditor firm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PricewaterhouseCoopers LLP</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2016</td>\n",
       "      <td>Auditor firm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PricewaterhouseCoopers LLP</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2012</td>\n",
       "      <td>Auditor firm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PricewaterhouseCoopers LLP</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2008</td>\n",
       "      <td>Auditor firm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PricewaterhouseCoopers LLP</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AIG</td>\n",
       "      <td>5272</td>\n",
       "      <td>2004</td>\n",
       "      <td>Auditor firm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PricewaterhouseCoopers LLP</td>\n",
       "      <td>section_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company   cik  year                               variable value_usd  \\\n",
       "0      AIG  5272  2020                         Total revenues    43,736   \n",
       "1      AIG  5272  2016                         Total revenues    52,367   \n",
       "2      AIG  5272  2012                         Total revenues    65,656   \n",
       "3      AIG  5272  2008                         Total revenues    11,777   \n",
       "4      AIG  5272  2004                         Total revenues    98,615   \n",
       "5      AIG  5272  2020  Net income (loss) attributable to AIG    -5,944   \n",
       "6      AIG  5272  2016  Net income (loss) attributable to AIG     3,348   \n",
       "7      AIG  5272  2012  Net income (loss) attributable to AIG     3,438   \n",
       "8      AIG  5272  2008  Net income (loss) attributable to AIG  -101,784   \n",
       "9      AIG  5272  2004  Net income (loss) attributable to AIG     9,731   \n",
       "10     AIG  5272  2020                           Auditor firm       NaN   \n",
       "11     AIG  5272  2016                           Auditor firm       NaN   \n",
       "12     AIG  5272  2012                           Auditor firm       NaN   \n",
       "13     AIG  5272  2008                           Auditor firm       NaN   \n",
       "14     AIG  5272  2004                           Auditor firm       NaN   \n",
       "\n",
       "            unit              category_value    section  \n",
       "0   USD millions                         NaN  section_8  \n",
       "1   USD millions                         NaN  section_8  \n",
       "2   USD millions                         NaN  section_8  \n",
       "3   USD millions                         NaN  section_8  \n",
       "4   USD millions                         NaN  section_8  \n",
       "5   USD millions                         NaN  section_8  \n",
       "6   USD millions                         NaN  section_8  \n",
       "7   USD millions                         NaN  section_8  \n",
       "8   USD millions                         NaN  section_8  \n",
       "9   USD millions                         NaN  section_8  \n",
       "10           NaN  PricewaterhouseCoopers LLP  section_8  \n",
       "11           NaN  PricewaterhouseCoopers LLP  section_8  \n",
       "12           NaN  PricewaterhouseCoopers LLP  section_8  \n",
       "13           NaN  PricewaterhouseCoopers LLP  section_8  \n",
       "14           NaN  PricewaterhouseCoopers LLP  section_8  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth = pd.read_csv(\"GroundTruthData_v1.csv\")\n",
    "df_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b805196-4e90-4b09-9a17-210728d73b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
