{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8af0e33-f6a3-4be9-a6d5-ccbda6ac56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iam herer\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langchain_experimental.text_splitter import SemanticChunker\n",
    "    _HAS_SEM = True\n",
    "    print(\"iam here\")\n",
    "except Exception:\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    _HAS_SEM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b4853cd-9f3f-40a8-9d96-33cb6a65ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LangChain retriever: stream from Spark to FAISS ---\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ec40c-161c-49ae-b306-683f00f6a59e",
   "metadata": {},
   "source": [
    "### 1. Loading Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ea83ee7-ae54-481c-90fc-5d5d05c71a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab981d089a484163bfa5bbcb72748a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Stream the dataset to avoid loading everything in memory\n",
    "ds = load_dataset(\"eloukas/edgar-corpus\", \"full\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd15a3c7-9209-4e54-a30c-dfe68b411840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 22 AIG rows to aig_edgar.jsonl.gz\n"
     ]
    }
   ],
   "source": [
    "# it never holds the whole dataset in memory, and the gzip keeps the file small.\n",
    "import json, gzip, os\n",
    "\n",
    "AIG_CIK = \"0000005272\"   # AIG\n",
    "OUT_PATH = \"aig_edgar.jsonl.gz\"  # compact on-disk buffer for Spark\n",
    "\n",
    "# # Stream the full split; no huge RAM spikes\n",
    "# ds = load_dataset(\"eloukas/edgar-corpus\", \"full\", split=\"train\", streaming=True)\n",
    "\n",
    "# Write only matching rows to newline-delimited JSON (gzipped)\n",
    "count = 0\n",
    "with gzip.open(OUT_PATH, \"wt\", encoding=\"utf-8\") as f:\n",
    "    for row in ds:\n",
    "        # rows have keys like: filename, cik, year, section_1, section_1A, ...\n",
    "        if str(row.get(\"cik\", \"\")).zfill(10) == AIG_CIK:\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "            count += 1\n",
    "\n",
    "print(f\"Wrote {count} AIG rows to {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bf01030-3a65-42d0-9d21-2621719f4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/10 17:39:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/09/10 17:39:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----+\n",
      "|filename     |cik       |year|\n",
      "+-------------+----------+----+\n",
      "|5272_1994.txt|0000005272|1994|\n",
      "|5272_1995.txt|0000005272|1995|\n",
      "|5272_1998.txt|0000005272|1998|\n",
      "|5272_1999.txt|0000005272|1999|\n",
      "|5272_2000.txt|0000005272|2000|\n",
      "|5272_2001.txt|0000005272|2001|\n",
      "|5272_2003.htm|0000005272|2003|\n",
      "|5272_2004.htm|0000005272|2004|\n",
      "|5272_2005.htm|0000005272|2005|\n",
      "|5272_2006.htm|0000005272|2006|\n",
      "+-------------+----------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved AIG subset to parquet_aig_edgar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"AIG-EDGAR\")\n",
    "    # tweak as you like; driver mem helps if you inspect a lot at once\n",
    "    .config(\"spark.driver.memory\", \"6g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Read the gzipped JSONL directly\n",
    "aig_df = spark.read.json(OUT_PATH)\n",
    "\n",
    "# (Optional) normalize CIK to 10-digit string for consistency\n",
    "from pyspark.sql.functions import lpad, col\n",
    "aig_df = aig_df.withColumn(\"cik\", lpad(col(\"cik\").cast(\"string\"), 10, \"0\"))\n",
    "\n",
    "# Inspect a few rows\n",
    "aig_df.select(\"filename\", \"cik\", \"year\").show(10, truncate=False)\n",
    "\n",
    "# Persist to Parquet (columnar, splittable, great for Spark)\n",
    "PARQUET_DIR = \"parquet_aig_edgar\"\n",
    "aig_df.write.mode(\"overwrite\").parquet(PARQUET_DIR)\n",
    "\n",
    "print(f\"Saved AIG subset to {PARQUET_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8bbbae-1596-4792-bac3-e8ec901f6eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>filename</th>\n",
       "      <th>section_1</th>\n",
       "      <th>section_10</th>\n",
       "      <th>section_11</th>\n",
       "      <th>section_12</th>\n",
       "      <th>section_13</th>\n",
       "      <th>section_14</th>\n",
       "      <th>section_15</th>\n",
       "      <th>section_1A</th>\n",
       "      <th>...</th>\n",
       "      <th>section_4</th>\n",
       "      <th>section_5</th>\n",
       "      <th>section_6</th>\n",
       "      <th>section_7</th>\n",
       "      <th>section_7A</th>\n",
       "      <th>section_8</th>\n",
       "      <th>section_9</th>\n",
       "      <th>section_9A</th>\n",
       "      <th>section_9B</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000005272</td>\n",
       "      <td>5272_1994.txt</td>\n",
       "      <td>ITEM 1. BUSINESS\\nAmerican International Group...</td>\n",
       "      <td>ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...</td>\n",
       "      <td>ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...</td>\n",
       "      <td>ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...</td>\n",
       "      <td>ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...</td>\n",
       "      <td>ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...</td>\n",
       "      <td>ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...</td>\n",
       "      <td>ITEM 6. SELECTED FINANCIAL DATA\\nAMERICAN INTE...</td>\n",
       "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
       "      <td></td>\n",
       "      <td>ITEM 8. FINANCIAL STATEMENTS AND SUPPLEMENTARY...</td>\n",
       "      <td>ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000005272</td>\n",
       "      <td>5272_1995.txt</td>\n",
       "      <td>ITEM 1. BUSINESS\\nAmerican International Group...</td>\n",
       "      <td>ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...</td>\n",
       "      <td>ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...</td>\n",
       "      <td>ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...</td>\n",
       "      <td>ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...</td>\n",
       "      <td>ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...</td>\n",
       "      <td>ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...</td>\n",
       "      <td>ITEM 6. SELECTED FINANCIAL DATA AMERICAN INTER...</td>\n",
       "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
       "      <td></td>\n",
       "      <td>ITEM 8. Financial Statements and Supplementary...</td>\n",
       "      <td>ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cik       filename  \\\n",
       "0  0000005272  5272_1994.txt   \n",
       "1  0000005272  5272_1995.txt   \n",
       "\n",
       "                                           section_1  \\\n",
       "0  ITEM 1. BUSINESS\\nAmerican International Group...   \n",
       "1  ITEM 1. BUSINESS\\nAmerican International Group...   \n",
       "\n",
       "                                          section_10  \\\n",
       "0  ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...   \n",
       "1  ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...   \n",
       "\n",
       "                                          section_11  \\\n",
       "0  ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...   \n",
       "1  ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...   \n",
       "\n",
       "                                          section_12  \\\n",
       "0  ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...   \n",
       "1  ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...   \n",
       "\n",
       "                                          section_13  \\\n",
       "0  ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...   \n",
       "1  ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...   \n",
       "\n",
       "                                          section_14 section_15 section_1A  \\\n",
       "0  ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...                         \n",
       "1  ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...                         \n",
       "\n",
       "   ...                                          section_4  \\\n",
       "0  ...  ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...   \n",
       "1  ...  ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...   \n",
       "\n",
       "                                           section_5  \\\n",
       "0  ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...   \n",
       "1  ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...   \n",
       "\n",
       "                                           section_6  \\\n",
       "0  ITEM 6. SELECTED FINANCIAL DATA\\nAMERICAN INTE...   \n",
       "1  ITEM 6. SELECTED FINANCIAL DATA AMERICAN INTER...   \n",
       "\n",
       "                                           section_7 section_7A  \\\n",
       "0  ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...              \n",
       "1  ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...              \n",
       "\n",
       "                                           section_8  \\\n",
       "0  ITEM 8. FINANCIAL STATEMENTS AND SUPPLEMENTARY...   \n",
       "1  ITEM 8. Financial Statements and Supplementary...   \n",
       "\n",
       "                                           section_9 section_9A section_9B  \\\n",
       "0  ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...                         \n",
       "1  ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...                         \n",
       "\n",
       "   year  \n",
       "0  1994  \n",
       "1  1995  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aig_df.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d279a2-3927-44b4-9df3-29c2b1bfd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import google.generativeai as genai\n",
    "# api_key = \"AIzaSyDz3kL0XL7QogHsDPh_g596Raj2CbpyMmQ\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = api_key # or set in your shell\n",
    "# genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41d2eb5b-306d-4410-b249-4aa075f625bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# dim = len(embeddings.embed_query(\"dimension probe\"))\n",
    "# print(\"Embedding dimension:\", dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faffb33b-7386-4d2b-ab0c-f7fc3409ef66",
   "metadata": {},
   "source": [
    "### 2. Preparing Parent Document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e7f9186-c724-41e4-b937-b4702e2f5fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(\n",
    "    model_name=\"text-embedding-004\",  # Gemini family embedding model\n",
    "    project=\"hd-datascience-np\",\n",
    "    location=\"us-central1\",\n",
    ")\n",
    "\n",
    "dim = len(embeddings.embed_query(\"dimension probe\"))\n",
    "print(\"Embedding dimension:\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fa7ce89-1e49-41a8-bb08-463ffa4e613b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 23)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = aig_df.toPandas()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7b0d505-7721-431a-8a73-3b2ff19cbbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 378 parent docs across 20 sections.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Identify section columns dynamically\n",
    "section_cols: List[str] = [c for c in df.columns if c.startswith(\"section_\")]\n",
    "\n",
    "# Build parent docs (one per non-empty section cell)\n",
    "parents: List[Document] = []\n",
    "parent_ids: List[str] = []\n",
    "\n",
    "for row in df.itertuples(index=False):\n",
    "    base_meta = {\n",
    "        \"filename\": getattr(row, \"filename\"),\n",
    "        \"cik\": getattr(row, \"cik\"),\n",
    "        \"year\": getattr(row, \"year\"),\n",
    "    }\n",
    "    for sec in section_cols:\n",
    "        content = getattr(row, sec)\n",
    "        if not content or not str(content).strip():\n",
    "            continue\n",
    "\n",
    "        parent_id = f\"{base_meta['filename']}#{sec}\"   # stable per (file, section)\n",
    "        doc = Document(\n",
    "            page_content=str(content),\n",
    "            metadata={\n",
    "                **base_meta,\n",
    "                \"section\": sec,\n",
    "                \"parent_id\": parent_id,\n",
    "            },\n",
    "        )\n",
    "        parents.append(doc)\n",
    "        parent_ids.append(parent_id)\n",
    "\n",
    "print(f\"Prepared {len(parents)} parent docs across {len(section_cols)} sections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06bab56e-5126-474e-8afc-54a287007aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(dim)  # inner product (works as cosine with normalized vectors)\n",
    "child_docstore = InMemoryDocstore()  # FAISS keeps its own docstore for children\n",
    "vectorstore = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=child_docstore,\n",
    "    index_to_docstore_id={},  # filled as we add children\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e6b9c48-06e3-4dc8-8f6c-5ffa1e495393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docstore for PARENTS\n",
    "parent_docstore = InMemoryStore()\n",
    "\n",
    "# # Splitter for children (tune sizes for your data)\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "# ---- SEMANTIC child splitter ----\n",
    "# breakpoint_threshold_type: \"percentile\" (95 = fewer, larger chunks) or \"standard_deviation\"\n",
    "# child_splitter = SemanticChunker(\n",
    "#     embeddings,\n",
    "#     breakpoint_threshold_type=\"percentile\",\n",
    "#     breakpoint_threshold_amount=95,\n",
    "# )\n",
    "\n",
    "# Build the ParentDocumentRetriever\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,       # children live here\n",
    "    docstore=parent_docstore,      # parents live here\n",
    "    child_splitter=child_splitter, # how to chunk parents into children\n",
    "    # parent_splitter=parent_splitter,        # tune recall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec72ac94-90e9-40f0-8b94-1603af622d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 378)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_ids), len(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9195c308-529c-4ced-9598-0b2858f9b43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'filename': '5272_1994.txt', 'cik': '0000005272', 'year': '1994', 'section': 'section_10', 'parent_id': '5272_1994.txt#section_10'}, page_content='ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF THE REGISTRANT\\nExcept for the information provided in Part I under the heading \"Directors and Executive Officers of the Registrant\", this item is omitted because a definitive proxy statement which involves the election of directors will be filed with the Securities and Exchange Commission not later than 120 days after the close of the fiscal year pursuant to Regulation 14A.\\nITEM 11.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676ac86-afe3-45d3-b013-563dcd3bbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent docs; c`d and indexed\n",
    "retriever.add_documents(parents, ids=parent_ids)\n",
    "print(\"Loaded parents and auto-chunked children into FAISS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe359c45-b09d-4d4f-a678-f551ad9ec596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParentDocumentRetriever(vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f8ded779750>, docstore=<langchain_core.stores.InMemoryStore object at 0x7f8ded77b8b0>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7f8e24ae2170>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "196139bf-ab10-48f3-96da-af664d117a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_DIR = \"./artifacts\"\n",
    "FAISS_DIR  = os.path.join(ARTIFACT_DIR, \"faiss_child_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "870e8070-270b-4d7f-ae6d-75d516aaa294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FAISS to: ./artifacts/faiss_child_store\n"
     ]
    }
   ],
   "source": [
    "# Save FAISS (child chunks)\n",
    "vectorstore.save_local(FAISS_DIR)\n",
    "\n",
    "# Parents are already persisted automatically to PARENT_DIR via LocalFileStore\n",
    "print(\"Saved FAISS to:\", FAISS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50947e62-428c-46d2-b23e-7cee85e8344c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Retrieval example (returns full parent docs for the matching child chunks)\n",
    "query = \"what is the total revenue\"\n",
    "results = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2563e33-46eb-41d7-8653-85a34b4a244c",
   "metadata": {},
   "source": [
    "### Retreive and Extract Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e868e08-ac02-4451-bbab-3a792533c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract_Details = \"\"\"\n",
    "## Role\n",
    "You are an extraction analyst. Read the provided document content and metadata to extract AIG facts.\n",
    "\n",
    "## Targets (extract EXACT text as written in the document body)\n",
    "- Total Revenue\n",
    "- Net income (loss) attributable to AIG\n",
    "- Auditor firm (e.g., “PricewaterhouseCoopers LLP”, “KPMG LLP”, “Deloitte & Touche LLP”)\n",
    "\n",
    "## Metadata Rules (authoritative)\n",
    "- year: use {year} if provided in metadata; do not infer from text if metadata exists.\n",
    "- section/source:\n",
    "  - Prefer {parent_id} (e.g., \"5272_2020.htm#section_9B\") if present.\n",
    "  - Else use {section} (e.g., \"section_9B\").\n",
    "  - If neither present, use the clearest section header found in the text (e.g., \"Item 7\", \"Item 8\").\n",
    "\n",
    "## Hints (don’t guess)\n",
    "- “Total Revenue” may appear as “Total revenues”, “Consolidated total revenues”.\n",
    "- “Net income (loss) attributable to AIG” might appear as “Net income attributable to AIG/common shareholders”.\n",
    "- For the auditor, return the firm NAME only (not the report title).\n",
    "- If any one of the three target fields (Total Revenue, Net income..., Auditor) is missing, return exactly: None\n",
    "\n",
    "## Output (STRICT)\n",
    "- Return EXACTLY one line with 5 fields separated by \" || \"\n",
    "  1) Total Revenue\n",
    "  2) Net income (loss) attributable to AIG\n",
    "  3) Auditor firm\n",
    "  4) year\n",
    "  5) section/source (prefer parent_id; else section; else header text)\n",
    "- No extra text, labels, or quotes.\n",
    "- Preserve numbers/formatting as written (keep $, commas, parentheses, “million/billion”).\n",
    "\n",
    "## Edge Rules\n",
    "- If both “Net income” and “Net loss” variants appear, choose the one explicitly “attributable to AIG”.\n",
    "- Prefer first unambiguous occurrence in MD&A/Financial Statements (Items 7/8) when multiple appear.\n",
    "- Never infer the auditor from signatures without the firm’s name.\n",
    "\n",
    "## Tiny Examples\n",
    "\n",
    "[Example A — all present]\n",
    "Meta: year=2019, section=section_7, parent_id=5272_2019.htm#section_7\n",
    "Text: “Total revenues were $52.1 billion… Net income (loss) attributable to AIG was $(6.7) billion… audited by PricewaterhouseCoopers LLP…”\n",
    "Output:\n",
    "$52.1 billion || $(6.7) billion || PricewaterhouseCoopers LLP || 2019 || 5272_2019.htm#section_7\n",
    "\n",
    "[Example B — missing a target → None]\n",
    "Meta: year=2016, section=section_7A, parent_id=5272_2016.htm#section_7A\n",
    "Text: “Total revenues were $39.8 billion… [no ‘net income attributable to AIG’]…”\n",
    "Output:\n",
    "None\n",
    "\n",
    "## Document (body text):\n",
    "{document}\n",
    "\n",
    "## Metadata:\n",
    "filename={filename}\n",
    "year={year}\n",
    "section={section}\n",
    "parent_id={parent_id}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23e81f1f-38cf-4c61-ba4b-1902c6e8821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI # Import the Google Generative AI class\n",
    "import os\n",
    "\n",
    "# Optional: Set your API key if it's not already in your environment variables\n",
    "# from google.colab import userdata # Use this if you are in a Colab notebook\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
    "PROJECT_ID = \"hd-datascience-np\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "prompt_template_v1 = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", Extract_Details)\n",
    "])\n",
    "\n",
    "# Choose model: \"gemini-1.5-flash\" (fast/cheap) or \"gemini-1.5-pro\" (higher quality)\n",
    "llm_1 = ChatVertexAI(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=1024,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    api_transport=\"grpc\",   # good perf\n",
    ")\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"what was the Total revenue of aig in 2016\")\n",
    "\n",
    "# docs = ensemble_retriever.get_relevant_documents(\"what was the Total revenue of aig in 2016\")\n",
    "\n",
    "rag_chain = prompt_template_v1 | llm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c0deee8-8900-4a52-9df8-99ca1a9fe89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_details_rag = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b03a55c-442b-41e7-936f-473adc2de26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '5272_2017.htm', 'year': '2017', 'section': 'section_7', 'parent_id': '5272_2017.htm#section_7'}\n",
      "{'filename': '5272_2016.htm', 'year': '2016', 'section': 'section_7', 'parent_id': '5272_2016.htm#section_7'}\n",
      "{'filename': '5272_2016.htm', 'year': '2016', 'section': 'section_1A', 'parent_id': '5272_2016.htm#section_1A'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print({\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "    })\n",
    "    out = rag_chain.invoke({\n",
    "            \"document\": doc.page_content,\n",
    "            \"filename\": doc.metadata.get(\"filename\"),\n",
    "            \"year\": doc.metadata.get(\"year\"),\n",
    "            \"section\": doc.metadata.get(\"section\"),\n",
    "            \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        })\n",
    "\n",
    "    content = getattr(out, \"content\", out)\n",
    "    if content is None:\n",
    "        continue\n",
    "\n",
    "    text = str(content).strip()\n",
    "    \n",
    "    # Skip empty/placeholder outputs\n",
    "    if not text or text.lower() in {\"none\", \"null\", \"{}\", \"[]\"}:\n",
    "        continue\n",
    "    \n",
    "    # Invoke the chain with a query\n",
    "    extracted_details_rag.append({\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        # \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "        \"extracted\": text,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6a95c-d45e-4d40-ad19-fe4e71b0a962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
