{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8af0e33-f6a3-4be9-a6d5-ccbda6ac56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iam here\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langchain_experimental.text_splitter import SemanticChunker\n",
    "    _HAS_SEM = True\n",
    "    print(\"iam here\")\n",
    "except Exception:\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    _HAS_SEM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b4853cd-9f3f-40a8-9d96-33cb6a65ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LangChain retriever: stream from Spark to FAISS ---\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ec40c-161c-49ae-b306-683f00f6a59e",
   "metadata": {},
   "source": [
    "### 1. Loading Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea83ee7-ae54-481c-90fc-5d5d05c71a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anant/anaconda3/envs/spark/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Stream the dataset to avoid loading everything in memory\n",
    "ds = load_dataset(\"eloukas/edgar-corpus\", \"full\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd15a3c7-9209-4e54-a30c-dfe68b411840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 22 AIG rows to aig_edgar.jsonl.gz\n"
     ]
    }
   ],
   "source": [
    "# it never holds the whole dataset in memory, and the gzip keeps the file small.\n",
    "import json, gzip, os\n",
    "\n",
    "AIG_CIK = \"0000005272\"   # AIG\n",
    "OUT_PATH = \"aig_edgar.jsonl.gz\"  # compact on-disk buffer for Spark\n",
    "\n",
    "# # Stream the full split; no huge RAM spikes\n",
    "# ds = load_dataset(\"eloukas/edgar-corpus\", \"full\", split=\"train\", streaming=True)\n",
    "\n",
    "# Write only matching rows to newline-delimited JSON (gzipped)\n",
    "count = 0\n",
    "with gzip.open(OUT_PATH, \"wt\", encoding=\"utf-8\") as f:\n",
    "    for row in ds:\n",
    "        # rows have keys like: filename, cik, year, section_1, section_1A, ...\n",
    "        if str(row.get(\"cik\", \"\")).zfill(10) == AIG_CIK:\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "            count += 1\n",
    "\n",
    "print(f\"Wrote {count} AIG rows to {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf01030-3a65-42d0-9d21-2621719f4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/10 23:22:39 WARN Utils: Your hostname, Anants-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.163 instead (on interface en0)\n",
      "25/09/10 23:22:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/10 23:22:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/09/10 23:22:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----+\n",
      "|filename     |cik       |year|\n",
      "+-------------+----------+----+\n",
      "|5272_1994.txt|0000005272|1994|\n",
      "|5272_1995.txt|0000005272|1995|\n",
      "|5272_1998.txt|0000005272|1998|\n",
      "|5272_1999.txt|0000005272|1999|\n",
      "|5272_2000.txt|0000005272|2000|\n",
      "|5272_2001.txt|0000005272|2001|\n",
      "|5272_2003.htm|0000005272|2003|\n",
      "|5272_2004.htm|0000005272|2004|\n",
      "|5272_2005.htm|0000005272|2005|\n",
      "|5272_2006.htm|0000005272|2006|\n",
      "+-------------+----------+----+\n",
      "only showing top 10 rows\n",
      "Saved AIG subset to parquet_aig_edgar\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "AIG_CIK = \"0000005272\"\n",
    "OUT_PATH = \"aig_edgar.jsonl.gz\"\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"AIG-EDGAR\")\n",
    "    # tweak as you like; driver mem helps if you inspect a lot at once\n",
    "    .config(\"spark.driver.memory\", \"6g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Read the gzipped JSONL directly\n",
    "aig_df = spark.read.json(OUT_PATH)\n",
    "\n",
    "# (Optional) normalize CIK to 10-digit string for consistency\n",
    "from pyspark.sql.functions import lpad, col\n",
    "aig_df = aig_df.withColumn(\"cik\", lpad(col(\"cik\").cast(\"string\"), 10, \"0\"))\n",
    "\n",
    "# Inspect a few rows\n",
    "aig_df.select(\"filename\", \"cik\", \"year\").show(10, truncate=False)\n",
    "\n",
    "# Persist to Parquet (columnar, splittable, great for Spark)\n",
    "PARQUET_DIR = \"parquet_aig_edgar\"\n",
    "aig_df.write.mode(\"overwrite\").parquet(PARQUET_DIR)\n",
    "\n",
    "print(f\"Saved AIG subset to {PARQUET_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8bbbae-1596-4792-bac3-e8ec901f6eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>filename</th>\n",
       "      <th>section_1</th>\n",
       "      <th>section_10</th>\n",
       "      <th>section_11</th>\n",
       "      <th>section_12</th>\n",
       "      <th>section_13</th>\n",
       "      <th>section_14</th>\n",
       "      <th>section_15</th>\n",
       "      <th>section_1A</th>\n",
       "      <th>...</th>\n",
       "      <th>section_4</th>\n",
       "      <th>section_5</th>\n",
       "      <th>section_6</th>\n",
       "      <th>section_7</th>\n",
       "      <th>section_7A</th>\n",
       "      <th>section_8</th>\n",
       "      <th>section_9</th>\n",
       "      <th>section_9A</th>\n",
       "      <th>section_9B</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000005272</td>\n",
       "      <td>5272_1994.txt</td>\n",
       "      <td>ITEM 1. BUSINESS\\nAmerican International Group...</td>\n",
       "      <td>ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...</td>\n",
       "      <td>ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...</td>\n",
       "      <td>ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...</td>\n",
       "      <td>ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...</td>\n",
       "      <td>ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...</td>\n",
       "      <td>ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...</td>\n",
       "      <td>ITEM 6. SELECTED FINANCIAL DATA\\nAMERICAN INTE...</td>\n",
       "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
       "      <td></td>\n",
       "      <td>ITEM 8. FINANCIAL STATEMENTS AND SUPPLEMENTARY...</td>\n",
       "      <td>ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000005272</td>\n",
       "      <td>5272_1995.txt</td>\n",
       "      <td>ITEM 1. BUSINESS\\nAmerican International Group...</td>\n",
       "      <td>ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...</td>\n",
       "      <td>ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...</td>\n",
       "      <td>ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...</td>\n",
       "      <td>ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...</td>\n",
       "      <td>ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...</td>\n",
       "      <td>ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...</td>\n",
       "      <td>ITEM 6. SELECTED FINANCIAL DATA AMERICAN INTER...</td>\n",
       "      <td>ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...</td>\n",
       "      <td></td>\n",
       "      <td>ITEM 8. Financial Statements and Supplementary...</td>\n",
       "      <td>ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cik       filename  \\\n",
       "0  0000005272  5272_1994.txt   \n",
       "1  0000005272  5272_1995.txt   \n",
       "\n",
       "                                           section_1  \\\n",
       "0  ITEM 1. BUSINESS\\nAmerican International Group...   \n",
       "1  ITEM 1. BUSINESS\\nAmerican International Group...   \n",
       "\n",
       "                                          section_10  \\\n",
       "0  ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...   \n",
       "1  ITEM 10. DIRECTORS AND EXECUTIVE OFFICERS OF T...   \n",
       "\n",
       "                                          section_11  \\\n",
       "0  ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...   \n",
       "1  ITEM 11. EXECUTIVE COMPENSATION\\nThis item is ...   \n",
       "\n",
       "                                          section_12  \\\n",
       "0  ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...   \n",
       "1  ITEM 12. SECURITY OWNERSHIP OF CERTAIN BENEFIC...   \n",
       "\n",
       "                                          section_13  \\\n",
       "0  ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...   \n",
       "1  ITEM 13. CERTAIN RELATIONSHIPS AND RELATED TRA...   \n",
       "\n",
       "                                          section_14 section_15 section_1A  \\\n",
       "0  ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...                         \n",
       "1  ITEM 14. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...                         \n",
       "\n",
       "   ...                                          section_4  \\\n",
       "0  ...  ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...   \n",
       "1  ...  ITEM 4. SUBMISSION OF MATTERS TO A VOTE OF SEC...   \n",
       "\n",
       "                                           section_5  \\\n",
       "0  ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...   \n",
       "1  ITEM 5. MARKET FOR THE REGISTRANT'S COMMON STO...   \n",
       "\n",
       "                                           section_6  \\\n",
       "0  ITEM 6. SELECTED FINANCIAL DATA\\nAMERICAN INTE...   \n",
       "1  ITEM 6. SELECTED FINANCIAL DATA AMERICAN INTER...   \n",
       "\n",
       "                                           section_7 section_7A  \\\n",
       "0  ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...              \n",
       "1  ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS O...              \n",
       "\n",
       "                                           section_8  \\\n",
       "0  ITEM 8. FINANCIAL STATEMENTS AND SUPPLEMENTARY...   \n",
       "1  ITEM 8. Financial Statements and Supplementary...   \n",
       "\n",
       "                                           section_9 section_9A section_9B  \\\n",
       "0  ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...                         \n",
       "1  ITEM 9. CHANGES IN AND DISAGREEMENTS WITH ACCO...                         \n",
       "\n",
       "   year  \n",
       "0  1994  \n",
       "1  1995  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aig_df.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d279a2-3927-44b4-9df3-29c2b1bfd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import google.generativeai as genai\n",
    "# api_key = \"AIzaSyDz3kL0XL7QogHsDPh_g596Raj2CbpyMmQ\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = api_key # or set in your shell\n",
    "# genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41d2eb5b-306d-4410-b249-4aa075f625bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# dim = len(embeddings.embed_query(\"dimension probe\"))\n",
    "# print(\"Embedding dimension:\", dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faffb33b-7386-4d2b-ab0c-f7fc3409ef66",
   "metadata": {},
   "source": [
    "### 2. Preparing Parent Document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7f9186-c724-41e4-b937-b4702e2f5fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anant/anaconda3/envs/spark/lib/python3.11/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(\n",
    "    model_name=\"text-embedding-004\",  # Gemini family embedding model\n",
    "    project=\"drift-sense\",\n",
    "    location=\"us-central1\",\n",
    ")\n",
    "\n",
    "dim = len(embeddings.embed_query(\"dimension probe\"))\n",
    "print(\"Embedding dimension:\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa7ce89-1e49-41a8-bb08-463ffa4e613b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 23)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = aig_df.toPandas()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b0d505-7721-431a-8a73-3b2ff19cbbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 378 parent docs across 20 sections.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Identify section columns dynamically\n",
    "section_cols: List[str] = [c for c in df.columns if c.startswith(\"section_\")]\n",
    "\n",
    "# Build parent docs (one per non-empty section cell)\n",
    "parents: List[Document] = []\n",
    "parent_ids: List[str] = []\n",
    "\n",
    "for row in df.itertuples(index=False):\n",
    "    base_meta = {\n",
    "        \"filename\": getattr(row, \"filename\"),\n",
    "        \"cik\": getattr(row, \"cik\"),\n",
    "        \"year\": getattr(row, \"year\"),\n",
    "    }\n",
    "    for sec in section_cols:\n",
    "        content = getattr(row, sec)\n",
    "        if not content or not str(content).strip():\n",
    "            continue\n",
    "\n",
    "        parent_id = f\"{base_meta['filename']}#{sec}\"   # stable per (file, section)\n",
    "        doc = Document(\n",
    "            page_content=str(content),\n",
    "            metadata={\n",
    "                **base_meta,\n",
    "                \"section\": sec,\n",
    "                \"parent_id\": parent_id,\n",
    "            },\n",
    "        )\n",
    "        parents.append(doc)\n",
    "        parent_ids.append(parent_id)\n",
    "\n",
    "print(f\"Prepared {len(parents)} parent docs across {len(section_cols)} sections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06bab56e-5126-474e-8afc-54a287007aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(dim)  # inner product (works as cosine with normalized vectors)\n",
    "child_docstore = InMemoryDocstore()  # FAISS keeps its own docstore for children\n",
    "vectorstore = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=child_docstore,\n",
    "    index_to_docstore_id={},  # filled as we add children\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e6b9c48-06e3-4dc8-8f6c-5ffa1e495393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docstore for PARENTS\n",
    "parent_docstore = InMemoryStore()\n",
    "\n",
    "# # Splitter for children (tune sizes for your data)\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "# ---- SEMANTIC child splitter ----\n",
    "# breakpoint_threshold_type: \"percentile\" (95 = fewer, larger chunks) or \"standard_deviation\"\n",
    "# child_splitter = SemanticChunker(\n",
    "#     embeddings,\n",
    "#     breakpoint_threshold_type=\"percentile\",\n",
    "#     breakpoint_threshold_amount=95,\n",
    "# )\n",
    "\n",
    "# Build the ParentDocumentRetriever\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,       # children live here\n",
    "    docstore=parent_docstore,      # parents live here\n",
    "    child_splitter=child_splitter, # how to chunk parents into children\n",
    "    # parent_splitter=parent_splitter,        # tune recall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec72ac94-90e9-40f0-8b94-1603af622d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 378)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_ids), len(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2676ac86-afe3-45d3-b013-563dcd3bbdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parents and auto-chunked children into FAISS.\n"
     ]
    }
   ],
   "source": [
    "# Add parent docs; c`d and indexed\n",
    "retriever.add_documents(parents, ids=parent_ids)\n",
    "print(\"Loaded parents and auto-chunked children into FAISS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "196139bf-ab10-48f3-96da-af664d117a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FAISS to: ./artifacts/faiss_child_store\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ARTIFACT_DIR = \"./artifacts\"\n",
    "FAISS_DIR  = os.path.join(ARTIFACT_DIR, \"faiss_child_store\")\n",
    "# Save FAISS (child chunks)\n",
    "vectorstore.save_local(FAISS_DIR)\n",
    "\n",
    "# Parents are already persisted automatically to PARENT_DIR via LocalFileStore\n",
    "print(\"Saved FAISS to:\", FAISS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50947e62-428c-46d2-b23e-7cee85e8344c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/kfpdlprs34v26w9mq48wpb200000gn/T/ipykernel_78708/3366153146.py:4: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Retrieval example (returns full parent docs for the matching child chunks)\n",
    "query = \"what is the total revenue as reported in Financial report\"\n",
    "results = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2563e33-46eb-41d7-8653-85a34b4a244c",
   "metadata": {},
   "source": [
    "### Retreive and Extract Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e868e08-ac02-4451-bbab-3a792533c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract_Details = \"\"\"\n",
    "## Role\n",
    "You are an extraction analyst. Read the provided document content and metadata to extract AIG facts.\n",
    "\n",
    "## Targets (extract EXACT text as written in the document body)\n",
    "- Total Revenue\n",
    "- Net income (loss) attributable to AIG\n",
    "- Auditor firm (e.g., “PricewaterhouseCoopers LLP”, “KPMG LLP”, “Deloitte & Touche LLP”)\n",
    "\n",
    "## Metadata Rules (authoritative)\n",
    "- year: use {year} if provided in metadata; do not infer from text if metadata exists.\n",
    "- section/source:\n",
    "  - Prefer {parent_id} (e.g., \"5272_2020.htm#section_9B\") if present.\n",
    "  - Else use {section} (e.g., \"section_9B\").\n",
    "  - If neither present, use the clearest section header found in the text (e.g., \"Item 7\", \"Item 8\").\n",
    "\n",
    "## Hints (don’t guess)\n",
    "- “Total Revenue” may appear as “Total revenues”, “Consolidated total revenues”.\n",
    "- “Net income (loss) attributable to AIG” might appear as “Net income attributable to AIG/common shareholders”.\n",
    "- For the auditor, return the firm NAME only (not the report title).\n",
    "- If any one of the three target fields (Total Revenue, Net income..., Auditor) is missing, return exactly: None\n",
    "\n",
    "## Output (STRICT)\n",
    "- Return EXACTLY one line with 5 fields separated by \" || \"\n",
    "  1) Total Revenue\n",
    "  2) Net income (loss) attributable to AIG\n",
    "  3) Auditor firm\n",
    "  4) year\n",
    "  5) section/source (prefer parent_id; else section; else header text)\n",
    "- No extra text, labels, or quotes.\n",
    "- Preserve numbers/formatting as written (keep $, commas, parentheses, “million/billion”).\n",
    "\n",
    "## Edge Rules\n",
    "- If both “Net income” and “Net loss” variants appear, choose the one explicitly “attributable to AIG”.\n",
    "- Prefer first unambiguous occurrence in MD&A/Financial Statements (Items 7/8) when multiple appear.\n",
    "- Never infer the auditor from signatures without the firm’s name.\n",
    "\n",
    "## Tiny Examples\n",
    "\n",
    "[Example A — all present]\n",
    "Meta: year=2019, section=section_7, parent_id=5272_2019.htm#section_7\n",
    "Text: “Total revenues were $52.1 billion… Net income (loss) attributable to AIG was $(6.7) billion… audited by PricewaterhouseCoopers LLP…”\n",
    "Output:\n",
    "$52.1 billion || $(6.7) billion || PricewaterhouseCoopers LLP || 2019 || 5272_2019.htm#section_7\n",
    "\n",
    "[Example B — missing a target → None]\n",
    "Meta: year=2016, section=section_7A, parent_id=5272_2016.htm#section_7A\n",
    "Text: “Total revenues were $39.8 billion… [no ‘net income attributable to AIG’]…”\n",
    "Output:\n",
    "None\n",
    "\n",
    "## Document (body text):\n",
    "{document}\n",
    "\n",
    "## Metadata:\n",
    "filename={filename}\n",
    "year={year}\n",
    "section={section}\n",
    "parent_id={parent_id}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23e81f1f-38cf-4c61-ba4b-1902c6e8821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI # Import the Google Generative AI class\n",
    "import os\n",
    "\n",
    "# Optional: Set your API key if it's not already in your environment variables\n",
    "# from google.colab import userdata # Use this if you are in a Colab notebook\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
    "PROJECT_ID = \"hd-datascience-np\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "prompt_template_v1 = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", Extract_Details)\n",
    "])\n",
    "\n",
    "# # Choose model: \"gemini-1.5-flash\" (fast/cheap) or \"gemini-1.5-pro\" (higher quality)\n",
    "# llm_1 = ChatVertexAI(\n",
    "#     model_name=\"gemini-2.5-flash\",\n",
    "#     temperature=0,\n",
    "#     max_output_tokens=1024,\n",
    "#     project=PROJECT_ID,\n",
    "#     location=LOCATION,\n",
    "#     api_transport=\"grpc\",   # good perf\n",
    "# )\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "api_key = \"AIzaSyDz3kL0XL7QogHsDPh_g596Raj2CbpyMmQ\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key # or set in your shell\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm_1 = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",   # 2.5 Flash\n",
    "    # api_key can be omitted if GOOGLE_API_KEY is set\n",
    "    api_key=api_key,\n",
    "    temperature=0.0,\n",
    "    max_output_tokens=1024,\n",
    ")\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"what is the total revenue as reported in 2016 Financial report\")\n",
    "\n",
    "# docs = ensemble_retriever.get_relevant_documents(\"what was the Total revenue of aig in 2016\")\n",
    "\n",
    "rag_chain = prompt_template_v1 | llm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c0deee8-8900-4a52-9df8-99ca1a9fe89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_details_rag = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b03a55c-442b-41e7-936f-473adc2de26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.11s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for doc in tqdm(docs):\n",
    "    out = rag_chain.invoke({\n",
    "            \"document\": doc.page_content,\n",
    "            \"filename\": doc.metadata.get(\"filename\"),\n",
    "            \"year\": doc.metadata.get(\"year\"),\n",
    "            \"section\": doc.metadata.get(\"section\"),\n",
    "            \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        })\n",
    "\n",
    "    content = getattr(out, \"content\", out)\n",
    "    if content is None:\n",
    "        continue\n",
    "\n",
    "    text = str(content).strip()\n",
    "    \n",
    "    # Skip empty/placeholder outputs\n",
    "    if not text or text.lower() in {\"none\", \"null\", \"{}\", \"[]\"}:\n",
    "        continue\n",
    "    \n",
    "    # Invoke the chain with a query\n",
    "    extracted_details_rag.append({\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        # \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "        \"extracted\": text,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60e6a95c-d45e-4d40-ad19-fe4e71b0a962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': '5272_2016.htm',\n",
       "  'year': '2016',\n",
       "  'section': 'section_7',\n",
       "  'parent_id': '5272_2016.htm#section_7',\n",
       "  'extracted': '$52,364 million || $(8,007) million || None || 2016 || 5272_2016.htm#section_7'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_details_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab21fbe-9c94-4dc9-9c71-a7766d2019f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"what is the total revenue as reported in 2020 Financial report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e010150-00ed-4358-a6af-68bca7964959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:22<00:00,  7.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "extracted_details_rag = []\n",
    "for doc in tqdm(docs):\n",
    "    out = rag_chain.invoke({\n",
    "            \"document\": doc.page_content,\n",
    "            \"filename\": doc.metadata.get(\"filename\"),\n",
    "            \"year\": doc.metadata.get(\"year\"),\n",
    "            \"section\": doc.metadata.get(\"section\"),\n",
    "            \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        })\n",
    "\n",
    "    content = getattr(out, \"content\", out)\n",
    "    if content is None:\n",
    "        continue\n",
    "\n",
    "    text = str(content).strip()\n",
    "    \n",
    "    # Skip empty/placeholder outputs\n",
    "    if not text or text.lower() in {\"none\", \"null\", \"{}\", \"[]\"}:\n",
    "        continue\n",
    "    \n",
    "    # Invoke the chain with a query\n",
    "    extracted_details_rag.append({\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        # \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "        \"extracted\": text,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3584c80-818f-4653-9ab8-a96714f74186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': '5272_2020.htm',\n",
       "  'year': '2020',\n",
       "  'section': 'section_8',\n",
       "  'parent_id': '5272_2020.htm#section_8',\n",
       "  'extracted': '$47,997 || $(5,973) || PricewaterhouseCoopers LLP || 2020 || 5272_2020.htm#section_8'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_details_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fa28e49-fc4b-4f47-9d6e-972efbd43eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:16<00:00,  8.45s/it]\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"what is the total revenue as reported in 2012 Financial report\")\n",
    "from tqdm import tqdm\n",
    "extracted_details_rag = []\n",
    "for doc in tqdm(docs):\n",
    "    out = rag_chain.invoke({\n",
    "            \"document\": doc.page_content,\n",
    "            \"filename\": doc.metadata.get(\"filename\"),\n",
    "            \"year\": doc.metadata.get(\"year\"),\n",
    "            \"section\": doc.metadata.get(\"section\"),\n",
    "            \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        })\n",
    "\n",
    "    content = getattr(out, \"content\", out)\n",
    "    if content is None:\n",
    "        continue\n",
    "\n",
    "    text = str(content).strip()\n",
    "    \n",
    "    # Skip empty/placeholder outputs\n",
    "    if not text or text.lower() in {\"none\", \"null\", \"{}\", \"[]\"}:\n",
    "        continue\n",
    "    \n",
    "    # Invoke the chain with a query\n",
    "    extracted_details_rag.append({\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        # \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "        \"extracted\": text,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e188e25-1ccf-49e1-b59d-42cf4cb9057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_details_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7887c1dc-dfe4-46a3-bd66-bc1999db341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:21<00:00,  7.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"what is the total revenue as reported in 2004 Financial report\")\n",
    "from tqdm import tqdm\n",
    "extracted_details_rag = []\n",
    "for doc in tqdm(docs):\n",
    "    out = rag_chain.invoke({\n",
    "            \"document\": doc.page_content,\n",
    "            \"filename\": doc.metadata.get(\"filename\"),\n",
    "            \"year\": doc.metadata.get(\"year\"),\n",
    "            \"section\": doc.metadata.get(\"section\"),\n",
    "            \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        })\n",
    "\n",
    "    content = getattr(out, \"content\", out)\n",
    "    if content is None:\n",
    "        continue\n",
    "\n",
    "    text = str(content).strip()\n",
    "    \n",
    "    # Skip empty/placeholder outputs\n",
    "    if not text or text.lower() in {\"none\", \"null\", \"{}\", \"[]\"}:\n",
    "        continue\n",
    "    \n",
    "    # Invoke the chain with a query\n",
    "    extracted_details_rag.append({\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        # \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "        \"extracted\": text,\n",
    "    })\n",
    "extracted_details_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3f4effd-f8d4-42c9-9850-00d05fbbc417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:20<00:00,  6.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'filename': '5272_2006.htm',\n",
       "  'year': '2006',\n",
       "  'section': 'section_8',\n",
       "  'parent_id': '5272_2006.htm#section_8',\n",
       "  'extracted': '$113,195 million || $14,049 million || PricewaterhouseCoopers LLP || 2006 || 5272_2006.htm#section_8'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"what is the total revenue as reported in 2008 Financial report\")\n",
    "from tqdm import tqdm\n",
    "extracted_details_rag = []\n",
    "for doc in tqdm(docs):\n",
    "    out = rag_chain.invoke({\n",
    "            \"document\": doc.page_content,\n",
    "            \"filename\": doc.metadata.get(\"filename\"),\n",
    "            \"year\": doc.metadata.get(\"year\"),\n",
    "            \"section\": doc.metadata.get(\"section\"),\n",
    "            \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        })\n",
    "\n",
    "    content = getattr(out, \"content\", out)\n",
    "    if content is None:\n",
    "        continue\n",
    "\n",
    "    text = str(content).strip()\n",
    "    \n",
    "    # Skip empty/placeholder outputs\n",
    "    if not text or text.lower() in {\"none\", \"null\", \"{}\", \"[]\"}:\n",
    "        continue\n",
    "    \n",
    "    # Invoke the chain with a query\n",
    "    extracted_details_rag.append({\n",
    "        \"filename\": doc.metadata.get(\"filename\"),\n",
    "        \"year\": doc.metadata.get(\"year\"),\n",
    "        \"section\": doc.metadata.get(\"section\"),\n",
    "        \"parent_id\": doc.metadata.get(\"parent_id\"),\n",
    "        # \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "        \"extracted\": text,\n",
    "    })\n",
    "extracted_details_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc08654-ba9a-4ba1-8ead-dc9a356416f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
